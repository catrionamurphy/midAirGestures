 @inproceedings{Shakeri_Williamson_Brewster_2017, 
    place={Oldenburg Germany}, 
    title={Novel Multimodal Feedback Techniques for In-Car Mid-Air Gesture Interaction}, 
    ISBN={978-1-4503-5150-8}, 
    url={https://dl.acm.org/doi/10.1145/3122986.3123011}, 
    DOI={10.1145/3122986.3123011}, 
    abstractNote={This paper presents an investigation into the effects of different feedback modalities on mid-air gesture interaction for infotainment systems in cars. Car crashes and near-crash events are most commonly caused by driver distraction. Mid-air interaction is a way of reducing driver distraction by reducing visual demand from infotainment. Despite a range of available modalities, feedback in mid-air gesture systems is generally provided through visual displays. We conducted a simulated driving study to investigate how different types of multimodal feedback can support in-air gestures. The effects of different feedback modalities on eye gaze behaviour, and the driving and gesturing tasks are considered. We found that feedback modality inﬂuenced gesturing behaviour. However, drivers corrected falsely executed gestures more often in non-visual conditions. Our ﬁndings show that non-visual feedback can reduce visual distraction signiﬁcantly.}, 
    booktitle={Proceedings of the 9th International Conference on Automotive User Interfaces and Interactive Vehicular Applications}, 
    publisher={ACM}, 
    author={Shakeri, Gözel and Williamson, John H. and Brewster, Stephen}, 
    year={2017}, 
    month={Sep}, 
    pages={84–93} }

 @inproceedings{Cabreira_Hwang_2016, 
    place={Gothenburg Sweden}, 
    title={How Do Novice Older Users Evaluate and Perform Mid-Air Gesture Interaction for the First Time?}, 
    ISBN={978-1-4503-4763-1}, 
    url={https://dl.acm.org/doi/10.1145/2971485.2996757}, 
    DOI={10.1145/2971485.2996757}, 
    abstractNote={Mid-air gesture interaction is often considered as a “natural” and “intuitive” input method, however, there has been little investigation of how older adults perceive and interact with these interfaces. We report the preliminary results of an experiment in which 20 younger and 20 older adults, without previous experience of gesturing in the air, are asked to perform 15 commonly used gestures and complete 5 computer tasks using mid-air gestures. We aim to learn how each age group engages with mid-air gestures regarding perceived easiness, confidence, intention of use and physical effort.}, 
    booktitle={Proceedings of the 9th Nordic Conference on Human-Computer Interaction}, publisher={ACM}, 
    author={Cabreira, Arthur Theil and Hwang, Faustina}, 
    year={2016}, 
    month={Oct}, 
    pages={1–6} }
    
 @inproceedings{Shakeri_Williamson_Brewster_2018, 
    place={Toronto ON Canada}, 
    title={May the Force Be with You: Ultrasound Haptic Feedback for Mid-Air Gesture Interaction in Cars}, 
    ISBN={978-1-4503-5946-7}, 
    url={https://dl.acm.org/doi/10.1145/3239060.3239081}, DOI={10.1145/3239060.3239081}, 
    abstractNote={The use of ultrasound haptic feedback for mid-air gestures in cars has been proposed to provide a sense of control over the user’s intended actions and to add touch to a touchless interaction. However, the impact of ultrasound feedback to the gesturing hand regarding lane deviation, eyes-off-the-road time (EORT) and perceived mental demand has not yet been measured. This paper investigates the impact of uni- and multimodal presentation of ultrasound feedback on the primary driving task and the secondary gesturing task in a simulated driving environment. The multimodal combinations of ultrasound included visual, auditory, and peripheral lights. We found that ultrasound feedback presented uni-modally and bi-modally resulted in signiﬁcantly less EORT compared to visual feedback. Our results suggest that multimodal ultrasound feedback for mid-air interaction decreases EORT whilst not compromising driving performance nor mental demand and thus can increase safety while driving.}, 
    booktitle={Proceedings of the 10th International Conference on Automotive User Interfaces and Interactive Vehicular Applications}, 
    publisher={ACM}, 
    author={Shakeri, Gözel and Williamson, John H. and Brewster, Stephen}, 
    year={2018}, 
    month={Sep}, 
    pages={1–10} }

 @inproceedings{Shakeri_Brewster_Williamson_Ng_2016, 
    place={San Jose California USA}, 
    title={Evaluating Haptic Feedback on a Steering Wheel in a Simulated Driving Scenario}, 
    ISBN={978-1-4503-4082-3}, 
    url={https://dl.acm.org/doi/10.1145/2851581.2892497}, DOI={10.1145/2851581.2892497}, 
    abstractNote={This paper investigates how perceivable haptic feedback patterns are using an actuated surface on a steering wheel. Six solenoids were embedded along the surface of the wheel, creating three bumps under each palm. The solenoids can be used to create a range of different tactile patterns. As a result of the design recommendation by Gallace et al. [11] maximally four of the six solenoids were actuated simultaneously, resulting in 57 patterns to test. A simulated driving study was conducted to investigate (1) the optimal number of actuated solenoids and (2) the most perceivable haptic patterns. A relationship between number of actuated solenoids and pattern identiﬁcation rate was established. Perception accuracy drops above three active solenoids. Haptic patterns mirrored symmetrically on both hands were perceived more accurately. Practical applications for displaying tactile messages on the steering wheel are e.g. dead angles, upcoming road conditions, navigation information (i.e. conveying information discretely to the driver).}, booktitle={Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems}, 
    publisher={ACM}, 
    author={Shakeri, Gözel and Brewster, Stephen A. and Williamson, John and Ng, Alexander}, 
    year={2016}, 
    month={May}, 
    pages={1744–1751} }

 @inproceedings{Shakeri_Williamson_Brewster_2017_2, 
    place={Glasgow UK}, 
    title={Bimodal feedback for in-car mid-air gesture interaction}, ISBN={978-1-4503-5543-8}, 
    url={https://dl.acm.org/doi/10.1145/3136755.3143033}, DOI={10.1145/3136755.3143033}, 
    abstractNote={This demonstration showcases novel multimodal feedback designs for in-car mid-air gesture interaction. It explores the potential of multimodal feedback types for mid-air gestures in cars and how these can reduce eyes-off-the-road time thus make driving safer. We will show four different bimodal feedback combinations to provide effective information about interaction with systems in a car. These feedback techniques are visual-auditory, auditory-ambient (peripheral vision), ambient-tactile, and tactile-auditory. Users can interact with the system after a short introduction, creating an exciting opportunity to deploy these displays in cars in the future.}, 
    booktitle={Proceedings of the 19th ACM International Conference on Multimodal Interaction}, 
    publisher={ACM}, 
    author={Shakeri, Gözel and Williamson, John H. and Brewster, Stephen A.}, year={2017}, 
    month={Nov}, 
    pages={518–519} }

 @inproceedings{Hessam_Zancanaro_Kavakli_Billinghurst_2017, 
    place={Brisbane Queensland Australia}, 
    title={Towards optimization of mid-air gestures for in-vehicle interactions}, ISBN={978-1-4503-5379-3}, 
    url={https://dl.acm.org/doi/10.1145/3152771.3152785}, DOI={10.1145/3152771.3152785}, 
    booktitle={Proceedings of the 29th Australian Conference on Computer-Human Interaction}, 
    publisher={ACM}, 
    author={Hessam, Jahani F. and Zancanaro, Massimo and Kavakli, Manolya and Billinghurst, Mark}, 
    year={2017}, 
    month={Nov}, 
    pages={126–134} }

 @inproceedings{Väänänen-Vainio-Mattila_Heikkinen_Farooq_Evreinov_Mäkinen_Raisamo_2014,    place={Melbourne, Victoria, Australia}, 
    title={User experience and expectations of haptic feedback in in-car interaction}, ISBN={978-1-4503-3304-7}, url={http://dl.acm.org/citation.cfm?doid=2677972.2677996}, DOI={10.1145/2677972.2677996}, 
    abstractNote={Haptic feedback based on the sense of touch and movement is a promising area of human-computer interaction in the car context. Most user studies on haptic feedback in the car have been controlled experiments of specific types of haptic stimuli. For the study presented in this paper, twelve participants tried novel haptic feedback prototypes and evaluated communication scenarios in the physical car context. Our aim was to understand user experiences and usage potential of haptic feedback in the car. The qualitative results show that haptic feedback may offer support for safety and social communication, but can be hard to interpret. We propose design considerations for incar haptics such as simplicity, subtleness and directionality.}, 
    booktitle={Proceedings of the 13th International Conference on Mobile and Ubiquitous Multimedia - MUM ’14}, 
    publisher={ACM Press}, author={Väänänen-Vainio-Mattila, Kaisa and Heikkinen, Jani and Farooq, Ahmed and Evreinov, Grigori and Mäkinen, Erno and Raisamo, Roope}, year={2014}, 
    pages={248–251} }

 @inproceedings{Di Campli San Vito_Brewster_Pollick_White_2017, 
    place={Glasgow UK}, 
    title={Thermal in-car interaction for navigation}, 
    ISBN={978-1-4503-5543-8}, 
    url={https://dl.acm.org/doi/10.1145/3136755.3143029}, DOI={10.1145/3136755.3143029}, 
    abstractNote={In this demonstration we show a thermal interaction design on the steering wheel for navigational cues in a car. Participants will be able to use a thermally enhanced steering wheel to follow instructions given in a turn-to-turn based navigation task in a virtual city. The thermal cues will be provided on both sides of the steering wheel and will indicate the turning direction by warming the corresponding side, while the opposite side is being cooled.}, booktitle={Proceedings of the 19th ACM International Conference on Multimodal Interaction}, 
    publisher={ACM}, 
    author={Di Campli San Vito, Patrizia and Brewster, Stephen A. and Pollick, Frank and White, Stuart}, 
    year={2017}, 
    month={Nov}, 
    pages={510–511} }

 @article{Young_Milne_Griffiths_Padfield_Blenkinsopp_Georgiou_2020, 
    title={Designing Mid-Air Haptic Gesture Controlled User Interfaces for Cars}, volume={4}, 
    ISSN={2573-0142, 2573-0142}, 
    DOI={10.1145/3397869}, 
    number={EICS}, 
    journal={Proceedings of the ACM on Human-Computer Interaction}, 
    author={Young, Gareth and Milne, Hamish and Griffiths, Daniel and Padfield, Elliot and Blenkinsopp, Robert and Georgiou, Orestis}, 
    year={2020}, 
    month={Jun}, 
    pages={1–23} }

 @inproceedings{Xuan_Daisong_Moli_Jingya_Xingtong_Siqi_2019, 
    place={Xiamen, China}, 
    title={Comparison on user experience of mid-air gesture interaction and traditional remotes control}, 
    ISBN={978-1-4503-7247-3}, url={http://dl.acm.org/citation.cfm?doid=3332169.3333570}, DOI={10.1145/3332169.3333570}, 
    abstractNote={Previous studies have explored mid-air gestures as a new interaction mode. However, very little is known about the user experience of using gestures for control and why it is better than traditional way. In this study, we invited users to use both gestures and a remote to control TV in a home environment setting and we assessed user experience in these two conditions. Results showed that while gesture control put more mental stress and cognitive load on users, it could improve the overall experience, especially in terms of unrestraint and efficiency, compared to remote control. Based on study results, discussion on user experience of mid-air gestures interaction and further study on a natural interactive experience evaluation mode were provided.}, 
    booktitle={Proceedings of the Seventh International Symposium of Chinese CHI on   - Chinese CHI ’19}, 
    publisher={ACM Press}, 
    author={Xuan, Li and Daisong, Guan and Moli, Zhou and Jingya, Zhang and Xingtong, Liu and Siqi, Li}, 
    year={2019}, 
    pages={16–22} }

 @inproceedings{Freeman_Brewster_Lantz_2016, 
    place={San Jose California USA}, 
    title={Do That, There: An Interaction Technique for Addressing In-Air Gesture Systems}, 
    ISBN={978-1-4503-3362-7}, 
    url={https://dl.acm.org/doi/10.1145/2858036.2858308}, DOI={10.1145/2858036.2858308}, 
    abstractNote={When users want to interact with an in-air gesture system, they must ﬁrst address it. This involves ﬁnding where to gesture so that their actions can be sensed, and how to direct their input towards that system so that they do not also affect others or cause unwanted effects. This is an important problem [6] which lacks a practical solution. We present an interaction technique which uses multimodal feedback to help users ad­ dress in-air gesture systems. The feedback tells them how (“do that”) and where (“there”) to gesture, using light, audio and tactile displays. By doing that there, users can direct their input to the system they wish to interact with, in a place where their gestures can be sensed. We discuss the design of our technique and three experiments investigating its use, ﬁnding that users can “do that” well (93.2\%–99.9\%) while accurately (51mm–80mm) and quickly (3.7s) ﬁnding “there”.}, 
    booktitle={Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems}, 
    publisher={ACM}, 
    author={Freeman, Euan and Brewster, Stephen and Lantz, Vuokko}, 
    year={2016}, 
    month={May}, 
    pages={2319–2331} }
    
@article{Department_for_Transport_2017, 
    title={Reported Road Casualties Great Britain: 2017}, author={{Department for Transport}}, 
    year={2017}, 
    pages={376} }
    
 @misc{Dow_2017, 
    title={Six Cars That Offer Gesture Control Technology}, url={https://uk.motor1.com/features/179171/gesture-control-technology-cars/}, 
    abstractNote={Sick of pressing buttons? Here are six cars that you can buy right now that each offer features that use gesture control technology.}, 
    journal={Six Cars That Offer Gesture Control Technology}, 
    author={Dow, Cat}, 
    year={2017}, 
    month={Sep} }

 @misc{Rommel_2020, 
    title={BMW gesture control: How it works? How to use it? | BimmerTech}, url={https://www.bimmer-tech.net/blog/item/124-bmw-gesture-control}, abstractNote={Want to control your iDrive features with a few simple gestures? See how BMW gesture control works, what cars it’s available for and how to easily activate it.}, 
    journal={BMW gesture control - the next level of iDrive interaction}, author={Rommel, Bianka}, 
    year={2020}, 
    month={Oct} }

 @misc{Bentley_2021, 
    title={Bentley New Flying Spur}, url={https://www.bentleymotors.com/en/models/new-flying-spur.html}, abstractNote={The new Flying Spur* is a unique fusion of breathtaking performance, contemporary design and intuitive technology.}, journal={en}, 
    author={Bentley}, 
    year={2021} }

 @article{Svangren_Skov_Kjeldskov_2017, 
    title={The Connected Car: An Empirical Study of Electric Cars as Mobile Digital Devices}, abstractNote={The amount of interactive digital technology in cars is increasing rapidly, and many new cars are shipped with connectivity. As a result, a new platform has emerged that holds potentials to facilitate many new and different interactions, both inside and outside the car. Within the area of HCI for cars, the focus has predominantly been on interactions with in-vehicle systems and applications of technology that is enabled through connectivity. However, we still lack in-depth empirical studies that provide details of the connected car, its use, opinions towards it, and how it integrates into people’s everyday lives. We report from a qualitative study of 13 households with connected electric cars. We present our findings in 3 themes of interaction through connectivity, updating and upgrading car software, and security and privacy. We further discuss our findings in 3 themes that might inform and inspire further mobile HCI research with the connected car.}, 
    author={Svangren, Michael K and Skov, Mikael B and Kjeldskov, Jesper}, 
    year={2017}, 
    pages={12} }


 @misc{Christou_2019, 
    title={Car technology influences more than 50\% of new vehicle purchases}, url={https://www.verdict.co.uk/car-technology-influence/}, 
    abstractNote={New research from German research institute GfK shows that the automotive industry has been smart to focus its attention on car technology innovation.}, 
    journal={In-vehicle technology influences more than 50\% of all new car purchases}, 
    author={Christou, Luke}, 
    year={2019}, 
    month={Jan} }

 @misc{CarDekho_2020, 
    title={Rolls-Royce Rolls Royce Dawn Black Badge On Road Price (Petrol), Features & Specs, Images}, url={https://www.cardekho.com/overview/Rolls-Royce_Dawn/Rolls-Royce_Dawn_Black_Badge.htm}, 
    abstractNote={Rolls-Royce Rolls Royce Dawn Black Badge Price in India is Rs 7.85 Cr. Check out Rolls Royce Dawn Black Badge colours, Features & Specifications, read Reviews, view Interior Images, & Mileage.}, journal={CarDekho}, 
    author={CarDekho}, 
    year={2020} }

    
 @misc{Mercedes,
    title={Mercedes-Benz S-Class Saloon: Technology}, url={https://www.mercedes-benz.co.uk/passengercars/mercedes-benz-cars/models/s-class/saloon-w222/comfort.html}, 
    abstractNote={Find out more about the superior driving characteristics of the Mercedes-Benz S-Class Saloon.}, 
    author={Mercedes},
    }

 @misc{Range_Rover, 
    title={Brochures - Shopping Tools - Land Rover UK}, url={https://www.landrover.co.uk/download-a-brochure/index.html}, abstractNote={Download a Land Rover vehicle brochure now. Take a closer look at the agile, dynamic and distinctive Land Rover’s and browse the details and specifications.}, 
    author={{Range Rover}} }

 @inproceedings{Villarreal_Narvaez_Vanderdonckt_Vatavu_Wobbrock_2020,
    place={Eindhoven Netherlands}, 
    title={A Systematic Review of Gesture Elicitation Studies: What Can We Learn from 216 Studies?}, 
    ISBN={978-1-4503-6974-9}, url={https://dl.acm.org/doi/10.1145/3357236.3395511}, DOI={10.1145/3357236.3395511}, 
    booktitle={Proceedings of the 2020 ACM Designing Interactive Systems Conference}, 
    publisher={ACM}, 
    author={Villarreal-Narvaez, Santiago and Vanderdonckt, Jean and Vatavu, Radu-Daniel and Wobbrock, Jacob O.}, 
    year={2020}, 
    month={Jul}, 
    pages={855–872} }
    
 @inproceedings{Wittorf_Jakobsen_2016, 
    place={Gothenburg Sweden}, 
    title={Eliciting Mid-Air Gestures for Wall-Display Interaction}, ISBN={978-1-4503-4763-1}, url={https://dl.acm.org/doi/10.1145/2971485.2971503}, DOI={10.1145/2971485.2971503}, 
    abstractNote={Freehand mid-air gestures are a promising input method for interacting with wall displays. However, work on mid-air gestures for wall-display interaction has mainly explored what is technically possible, which might not result in gestures that users would prefer. This paper presents a guessability study where 20 participants performed gestures for 25 actions on a three-meter wide display. Based on the resulting 1124 gestures, we describe user-deﬁned mid-air gestures for walldisplay interaction and characterize the types of gesture users prefer for this context. The resulting gestures were largely inﬂuenced by surface interaction; they tended to be larger and more physically-based than gestures elicited in previous studies using smaller displays.}, 
    booktitle={Proceedings of the 9th Nordic Conference on Human-Computer Interaction}, 
    publisher={ACM}, 
    author={Wittorf, Markus L. and Jakobsen, Mikkel R.}, 
    year={2016}, 
    month={Oct}, 
    pages={1–4} }
    
 @inproceedings{Weidner_Broll_2019, 
    place={Pisa Italy}, 
    title={Interact with your car: a user-elicited gesture set to inform future in-car user interfaces}, 
    ISBN={978-1-4503-7624-2}, url={https://dl.acm.org/doi/10.1145/3365610.3365625}, DOI={10.1145/3365610.3365625}, 
    abstractNote={In recent years, stereoscopic 3D (S3D) displays have shown promising results on user experience, for navigation, and critical warnings when applied in cars. However, previous studies have only investigated these displays in non-interactive use-cases. So far, interacting with stereoscopic 3D content in cars has not been studied. Hence, we investigated how people interact with large S3D dashboards in automated vehicles (SAE level 4). In a user-elicitation study (N=23), we asked participants to propose interaction techniques for 24 referents while sitting in a driving simulator. Based on video recordings and motion tracking data of 1104 proposed interactions containing gestures and other input modalities, we grouped the gestures per task. Overall, we can report a chance-corrected agreement rate of κ = 0.232 and by that, a medium agreement among participants. Based on the agreement rates, we defined two sets of gestures: a basic and a holistic version. Our results show that participants intuitively interact with S3D dashboards and that they prefer mid-air gestures that either directly manipulate the virtual object or operate on a proxy object. We further compare our results with similar results in different settings and provide insights on factors that have shaped our gesture set.}, 
    booktitle={Proceedings of the 18th International Conference on Mobile and Ubiquitous Multimedia}, 
    publisher={ACM}, 
    author={Weidner, Florian and Broll, Wolfgang}, 
    year={2019}, 
    month={Nov}, 
    pages={1–12} }
    
 @inproceedings{Vatavu_Zaiti_2014, 
    place={Newcastle Upon Tyne, United Kingdom}, 
    title={Leap gestures for TV: insights from an elicitation study}, ISBN={978-1-4503-2838-8}, url={http://dl.acm.org/citation.cfm?doid=2602299.2602316}, DOI={10.1145/2602299.2602316}, 
    abstractNote={We present insights from a gesture elicitation study in the context of interacting with TV, during which 18 participants contributed and rated the execution difficulty and recall likeliness of free-hand gestures for 21 distinct TV tasks. Our study complements previous work on gesture interaction design for the TV set with the first exploration of fine-grained resolution 3-D finger movements and hand pose gestures. We report lower agreement rates (.20) than previous gesture studies and 72.8\% recall rate and 15.8\% false positive recall, results that are explained by the complexity and variability of unconstrained finger gestures. Nevertheless, we report a large 82\% preference for gesture commands versus TV remote controls. We also confirm previous findings, such as people’s preferences for related gestures for dichotomous tasks, and we report low agreement rates for abstract tasks, such as “open browser” or “show channels list” in our specific TV scenario. In the end, we contribute a set of design guidelines for practitioners interested in free-hand finger and hand pose gestures for interactive TV scenarios, and we release a dataset of 378 Leap Motion gesture records consisting in finger position, direction, and velocity coordinates for further studies in the community. We see this exploration as a first step toward designing low-effort high-resolution finger gestures and hand poses for lean-back interaction with the TV set.}, 
    booktitle={Proceedings of the 2014 ACM international conference on Interactive experiences for TV and online video - TVX ’14}, 
    publisher={ACM Press}, 
    author={Vatavu, Radu-Daniel and Zaiti, Ionut-Alexandru}, 
    year={2014}, 
    pages={131–138} }

 @article{Vogiatzidakis_Koutsabasis_2018, 
    title={Gesture Elicitation Studies for Mid-Air Interaction: A Review}, 
    volume={2}, 
    DOI={10.3390/mti2040065}, 
    abstractNote={Mid-air interaction involves touchless manipulations of digital content or remote devices, based on sensor tracking of body movements and gestures. There are no established, universal gesture vocabularies for mid-air interactions with digital content or remote devices based on sensor tracking of body movements and gestures. On the contrary, it is widely acknowledged that the identification of appropriate gestures depends on the context of use, thus the identification of mid-air gestures is an important design decision. The method of gesture elicitation is increasingly applied by designers to help them identify appropriate gesture sets for mid-air applications. This paper presents a review of elicitation studies in mid-air interaction based on a selected set of 47 papers published within 2011&ndash;2018. It reports on: (1) the application domains of mid-air interactions examined; (2) the level of technological maturity of systems at hand; (3) the gesture elicitation procedure and its variations; (4) the appropriateness criteria for a gesture; (5) participants number and profile; (6) user evaluation methods (of the gesture vocabulary); (7) data analysis and related metrics. This paper confirms that the elicitation method has been applied extensively but with variability and some ambiguity and discusses under-explored research questions and potential improvements of related research.}, number={44}, 
    journal={Multimodal Technologies and Interaction}, 
    publisher={Multidisciplinary Digital Publishing Institute}, 
    author={Vogiatzidakis, Panagiotis and Koutsabasis, Panayiotis}, 
    year={2018}, 
    month={Dec}, 
    pages={65} }
    
 @article{Morris_Wobbrock_Wilson_2010, 
    title={Understanding Users’ Preferences for Surface Gestures}, 
    abstractNote={We compare two gesture sets for interactive surfaces—a set of gestures created by an end-user elicitation method and a set of gestures authored by three HCI researchers. Twenty-two participants who were blind to the gestures’ authorship evaluated 81 gestures presented and performed on a Microsoft Surface. Our findings indicate that participants preferred gestures authored by larger groups of people, such as those created by end-user elicitation methodologies or those proposed by more than one researcher. This preference pattern seems to arise in part because the HCI researchers proposed more physically and conceptually complex gestures than end-users. We discuss our findings in detail, including the implications for surface gesture design.}, 
    author={Morris, Meredith Ringel and Wobbrock, Jacob O and Wilson, Andrew D}, 
    year={2010}, 
    pages={8} }

 @misc{bentley_Bekker_2020, 
    title={2019 (Full Year) Global: Bentley Sales Worldwide}, url={https://www.best-selling-cars.com/global/2019-full-year-global-bentley-sales-worldwide/}, 
    abstractNote={In 2019, Bentley Motors increased worldwide sales by 5\% to 11,006 cars - the seventh consecutive year that Bentley sold over 10,000 vehicles.}, 
    journal={Car Sales Statistics}, 
    author={Bekker, Henk}, 
    year={2020}, 
    month={Jan} }

 @misc{mercedes_Bekker_2020, 
    title={2019 (Full Year) Global: Mercedes-Benz Sales Worldwide}, url={https://www.best-selling-cars.com/brands/2019-full-year-global-mercedes-benz-sales-worldwide/}, 
    abstractNote={In 2019, Mercedes-Benz sales worldwide increased by 1.3\% to a record 2,339,562 cars delivered. Global sales or Smart were down 9.3\%.}, 
    journal={Car Sales Statistics}, 
    author={Bekker, Henk}, 
    year={2020}, 
    month={Jan} }

 @misc{Rolls_Bekker_2020, 
    title={2019 (Full Year) Global: Rolls-Royce Sales Worldwide}, url={https://www.best-selling-cars.com/global/2019-full-year-global-rolls-royce-sales-worldwide/}, 
    abstractNote={In 2019, Rolls-Royce sales worldwide increased by a quarter to a new record 5,152 motor cars. The Cullinan SUV was in high demand.}, 
    journal={Car Sales Statistics}, 
    author={Bekker, Henk}, 
    year={2020}, 
    month={Jan} }

 @misc{Statista_2020, 
    title={Land Rover global sales by model 2013-2019}, url={https://www.statista.com/statistics/387780/land-rover-global-sales-by-model/}, abstractNote={This statistic shows the number of Land Rover cars sold globally from 2013 to 2019, categorized by model.}, 
    journal={Statista}, 
    author={Statista}, 
    year={2020}, 
    month={Jan} }

 @book{Coding_Basics_2014, 
    title={Setting Up Leap Motion with Python - Leap Motion and Python: Tutorial 1}, url={https://www.youtube.com/watch?v=T9k7rdY625M&ab_channel=CodingBasics}, 
    author={{Coding Basics}}, 
    year={2014}, 
    month={Jul} }

@misc{leapmotion_api_nodate,
	title = {{API} {Reference} — {Leap} {Motion} {Python} {SDK} v2.3 documentation},
	url = {https://developer-archive.leapmotion.com/documentation/v2/python/api/Leap_Classes.html},
	urldate = {2021-03-12},
	journal = {Leap Motion},
	author = {LeapMotion},
	file = {API Reference — Leap Motion Python SDK v2.3 documentation:C\:\\Users\\murph\\Zotero\\storage\\XSEK6292\\Leap_Classes.html:text/html},
}

 @inproceedings{Freeman_Brewster_Lantz_2015, 
    place={Cham}, series={Lecture Notes in Computer Science}, 
    title={Towards In-Air Gesture Control of Household Appliances with Limited Displays}, ISBN={978-3-319-22723-8}, 
    DOI={10.1007/978-3-319-22723-8_73}, 
    abstractNote={Recent technologies allow us to interact with our homes in novel ways, such as using in-air gestures for control. However, gestures require good feedback and small appliances, like lighting controls and thermostats, have limited, or no, display capabilities. Our research explores how other output types can be used to give users feedback about their gestures, instead, allowing small devices to give useful feedback. We describe the Gesture Thermostat, a gesture-controlled thermostat dial which gives multimodal gesture feedback.}, 
    booktitle={Human-Computer Interaction – INTERACT 2015}, 
    publisher={Springer International Publishing}, 
    author={Freeman, Euan and Brewster, Stephen and Lantz, Vuokko}, 
    editor={Abascal, Julio and Barbosa, Simone and Fetter, Mirko and Gross, Tom and Palanque, Philippe and Winckler, Marco}, 
    year={2015}, 
    pages={611–615}, 
    collection={Lecture Notes in Computer Science} }

 @misc{Haselton_2020, 
    title={Google announces new Nest Thermostat that uses radar to detect when you’re nearby}, url={https://www.cnbc.com/2020/10/12/google-announces-new-nest-thermostat-with-soli-radar.html}, 
    abstractNote={The Nest Thermostat has a completely new design that looks less clunky. Instead of rotating the face of the unit, you just touch and swipe down the side to increase or decrease the temperature.}, 
    journal={CNBC}, 
    author={Haselton, Todd}, 
    year={2020}, 
    month={Oct} }

 @article{Vogiatzidakis_Koutsabasis_2020, 
    title={Mid-Air Gesture Control of Multiple Home Devices in Spatial Augmented Reality Prototype}, 
    volume={4}, 
    DOI={10.3390/mti4030061}, 
    abstractNote={Touchless, mid-air gesture-based interactions with remote devices have been investigated as alternative or complementary to interactions based on remote controls and smartphones. Related studies focus on user elicitation of a gesture vocabulary for one or a few home devices and explore recommendations of respective gesture vocabularies without validating them by empirical testing with interactive prototypes. We have developed an interactive prototype based on spatial Augmented Reality (AR) of seven home devices. Each device responds to touchless gestures (identified from a previous elicitation study) via the MS Kinect sensor. Nineteen users participated in a two-phase test (with and without help provided by a virtual assistant) according to a scenario that required from each user to apply 41 gestural commands (19 unique). We report on main usability indicators: task success, task time, errors (false negative/positives), memorability, perceived usability, and user experience. The main conclusion is that mid-air interaction with multiple home devices is feasible, fairly easy to learn and apply, and enjoyable. The contributions of this paper are (a) validation of a previously elicited gesture set; (b) development of a spatial AR prototype for testing of mid-air gestures, and (c) extensive assessment of gestures and evidence in favor of mid-air interaction in smart environments.}, 
    number={33}, 
    journal={Multimodal Technologies and Interaction}, 
    publisher={Multidisciplinary Digital Publishing Institute}, 
    author={Vogiatzidakis, Panagiotis and Koutsabasis, Panayiotis}, 
    year={2020}, 
    month={Sep}, 
    pages={61} }

 @inproceedings{May_Gable_Walker_2017, 
    place={Oldenburg Germany}, 
    title={Designing an In-Vehicle Air Gesture Set Using Elicitation Methods}, ISBN={978-1-4503-5150-8}, url={https://dl.acm.org/doi/10.1145/3122986.3123015}, DOI={10.1145/3122986.3123015}, 
    abstractNote={In-air gestures have become more prevalent in the vehicle cockpit in recent years. However, air gesture interfaces are still quite young and users have very little experience with such interactions. In the vehicle, ease of use relates directly to driver safety. Previous work has suggested that gesture sets created through participatory methods tend to be easier for people to grasp and use than designer-designed sets. In the present study, two novel participatory design activities – an elicitation activity in which participants produced gestures, and an online survey in which they assessed the workload associated with those gestures – were conducted to assess possible air gestures for control of invehicle menus. A recommended gesture set is presented alongside broader recommendations for vehicle gesture design.}, 
    booktitle={Proceedings of the 9th International Conference on Automotive User Interfaces and Interactive Vehicular Applications}, 
    publisher={ACM}, 
    author={May, Keenan R. and Gable, Thomas M. and Walker, Bruce N.}, year={2017}, 
    month={Sep}, 
    pages={74–83} }

 @misc{Jakobsen_2016, 
    title={Mid-Air Interaction – Mikkel Rønne Jakobsen}, url={http://mikkelrj.dk/research/mid-air/}, 
    author={Jakobsen, Mikkel R.}, 
    year={2016} }

 @inproceedings{Cabreira_Hwang_2015, 
    place={Lincoln Lincolnshire United Kingdom}, 
    title={An analysis of mid-air gestures used across three platforms}, ISBN={978-1-4503-3643-7}, url={https://dl.acm.org/doi/10.1145/2783446.2783599}, DOI={10.1145/2783446.2783599}, 
    abstractNote={This study aims to compare the use of specific mid-air gestures across platforms (Microsoft Kinect, Leap Motion and Myo Armband) in order to identify the most recurrent gestures and their functions within the interface. 250 applications were analysed and 15 common gestures were mapped within this study. Results will contribute to wider research on mid-air gesture-based interfaces and assistive technology.}, 
    booktitle={Proceedings of the 2015 British HCI Conference}, 
    publisher={ACM}, 
    author={Cabreira, Arthur Theil and Hwang, Faustina}, 
    year={2015}, 
    month={Jul}, 
    pages={257–258} }

 @misc{Finnerty_2017, 
    title={This £177k SUV is most expensive Range Rover EVER - with TVs and fridges}, url={https://www.thesun.ie/motors/1862771/range-rover-svautobiography-is-most-expensive-model-ever-and-the-177000-suv-has-tv-screens-a-fridge-for-two-wine-bottles-massage-chairs-and-a-digital-butler/}, 
    abstractNote={LAND ROVER has unveiled its most expensive “Rangie” ever. The incredible £177,000 Range Rover SVAutobiography is packed with luxury more at home on a first class plane. The long wheelba…}, 
    journal={The Irish Sun}, 
    author={Finnerty, Joe}, 
    year={2017}, 
    month={Nov} }

 @inproceedings{Moser_Tscheligi_2015, 
    place={Boston Massachusetts}, 
    title={Physics-based gaming: exploring touch vs. mid-air gesture input}, 
    ISBN={978-1-4503-3590-4}, 
    url={https://dl.acm.org/doi/10.1145/2771839.2771899}, 
    DOI={10.1145/2771839.2771899}, 
    abstractNote={Physics-based games, like Cut the Rope, have become very popular and are now available on different operating systems with different input modalities. In a user study with 20 children aged 11 to 14 years, we investigated the differences in player experience when playing Cut the Rope on the tablet with touch gestures and on the computer with mid-air gestures using a Leap Motion. The quantitative data from the questionnaire revealed no substantial differences regarding the player experience, which might be due to the novelty effect of the Leap Motion mid-air gestures. However, the observations indicated several problems of accuracy and orientation when playing the game with mid-air gestures. This is due to the lack of hardware-based physical feedback when interacting with the Leap Motion and results in a different affordance that has to be considered in future physics based game design using mid-air gestures.}, 
    booktitle={Proceedings of the 14th International Conference on Interaction Design and Children}, publisher={ACM}, 
    author={Moser, Christiane and Tscheligi, Manfred}, 
    year={2015}, 
    month={Jun}, 
    pages={291–294} }

 @misc{OpenGameArt.org, 
    url={https://opengameart.org/}, 
    journal={OpenGameArt.org}, 
    publisher={OpenGameArt.org}, 
    author = {{Open Game Art}} }

 @misc{Eastwood_2015, 
    title={Animated Sine Wave two-ways with pygame and tkinter}, url={https://ericeastwood.com/blog/7/animated-sine-wave-two-ways-with-pygame-and-tkinter}, journal={Eric Eastwood Web Developer}, 
    author={Eastwood, Eric}, year={2015} }

 @misc{Conrad, title={Pygame Drawing Basics}, 
    url={https://sites.cs.ucsb.edu/~pconrad/cs5nm/topics/pygame/drawing/}, 
    journal={UC Santa Barbara}, 
    author={Conrad, P.} }

 @misc{Bradfield_2016, 
    title={Pygame Shmup Part 6: Sprite Animation · KCC Blog}, url={https://kidscancode.org/blog/2016/08/pygame_shmup_part_6/}, 
    journal={KidsCanCode}, 
    author={Bradfield, Chris}, 
    year={2016}, 
    month={Aug} }

 @misc{Nerd_Paradise, 
    title={PyGame Tutorial: Getting Started : Nerd Paradise}, 
    url={https://nerdparadise.com/programming/pygame/part1}, 
    journal={Nerd Paradise}, 
    author={{Nerd Paradise}} }

 @misc{ProgrammerSought, 
    title={[Study notes] Understanding of pitch, yaw, and roll in Leap motion equipment - Programmer Sought}, 
    url={https://www.programmersought.com/article/91805364249/}, journal={ProgrammerSought}, 
    author={ProgrammerSought} }

 @article{Perreault_1975, 
    title={Controlling Order-Effect Bias}, 
    volume={39}, 
    ISSN={0033-362X}, 
    number={4}, 
    journal={The Public Opinion Quarterly}, 
    publisher={[Oxford University Press, American Association for Public Opinion Research]}, author={Perreault, William D.}, 
    year={1975}, 
    pages={544–551} }
